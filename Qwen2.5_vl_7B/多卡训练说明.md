
## 多GPU训练启动指南

本文档旨在说明如何使用 `torchrun` 配合 `CUDA_VISIBLE_DEVICES` 环境变量进行单卡及多卡训练。

## 核心规则

在使用 `torchrun`进行多卡训练时，必须遵守以下规则：

> **`--nproc_per_node` 的数量必须严格等于 `CUDA_VISIBLE_DEVICES` 中列出的 GPU 数量。**

-----

## 使用示例

以下是一些常见的训练场景及其对应的启动命令。

### 1\. 使用单张特定GPU进行训练

如果您希望只使用服务器上的**一张**特定的 GPU（例如：5号卡），可以直接指定 `CUDA_VISIBLE_DEVICES` 并使用 `python` 启动脚本，无需 `torchrun`。

  - **目标：** 使用 `5` 号 GPU。
  - **命令：**
    ```bash
    CUDA_VISIBLE_DEVICES=5 python train.py
    ```

### 2\. 使用多张特定GPU进行训练

当您需要指定多张不连续或特定的 GPU 时，请使用 `torchrun`。

  - **目标：** 使用 `5, 6` 号两张 GPU。

  - **命令：** (`--nproc_per_node` 设置为 `2`)

    ```bash
    CUDA_VISIBLE_DEVICES=5,6 torchrun --nproc_per_node=2 train.py
    ```

  - **目标：** 使用 `5, 6, 7` 号三张 GPU。

  - **命令：** (`--nproc_per_node` 设置为 `3`)

    ```bash
    CUDA_VISIBLE_DEVICES=5,6,7 torchrun --nproc_per_node=3 train.py
    ```

### 3\. 使用服务器上所有可见的GPU进行训练

如果您希望使用服务器上所有可用的 GPU，且它们是连续的（或您不关心具体是哪几张卡），则**无需设置** `CUDA_VISIBLE_DEVICES` 环境变量。

  - **目标：** 使用服务器上所有可见的 `4` 张 GPU。
  - **注意：** 此命令假设服务器总共有4张可用的GPU。请根据实际GPU数量修改 `--nproc_per_node` 的值。
  - **命令：**
    ```bash
    torchrun --nproc_per_node=4 train.py
    ```